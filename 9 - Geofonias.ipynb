{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "V28",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vmartinezarias/Curso_Ecologia_Paisaje_y-Ecoacustica/blob/main/9%20-%20Geofonias.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verificar Procesadores"
      ],
      "metadata": {
        "id": "c1wkJuGmNuLO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhCy8Jqk-kQ9"
      },
      "outputs": [],
      "source": [
        "from psutil import cpu_count\n",
        "print(f\"Número de CPUs disponibles: {cpu_count(logical=True)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openpyxl"
      ],
      "metadata": {
        "id": "rbg7cooLBktB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANÁLISIS GEOFONÍAS (LLUVIA)\n",
        "Este algoritmo se basa Tras efectuar el cambio de nombre, se procede a correr el algoritmo de ruidos fuertes. Este es un  Script de Python, para identificar grabaciones acústicas con lluvia. Se basa en el trabajo realizado por Bedoya et al (2017)."
      ],
      "metadata": {
        "id": "bvuWQATAN7Nc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carga de paquetes requeridos"
      ],
      "metadata": {
        "id": "pYolB2H8OZ8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import soundfile as sf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import signal, stats\n",
        "import os\n",
        "import tqdm\n",
        "from multiprocessing import Pool\n",
        "import time\n",
        "from datetime import timedelta\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "1cvItXiIOc-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definir los parámetros de entrada del algoritmo"
      ],
      "metadata": {
        "id": "iNtsUmoROfrW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# **Parámetros de Entrada** (Definibles al inicio)\n",
        "ruta_datos = \"/content/drive/MyDrive/CursoPaisajeAudios/\"  # Carpeta raíz con audios\n",
        "folder_rain = \"/content/drive/MyDrive/Curso_Ecologia_Paisaje_Ecoacustica/resultados\"  # Carpeta para guardar resultados\n",
        "name_file = \"Resultado_lluvia.xlsx\"  # Nombre del archivo Excel de salida\n",
        "formatos = ['wav', 'WAV']  # Formatos aceptados\n",
        "n_cores = 50  # Número de núcleos para procesamiento paralelo\n",
        "exclude_these_sites = []  # Sitios a excluir\n",
        "\n",
        "# Crear la carpeta de resultados si no existe\n",
        "os.makedirs(folder_rain, exist_ok=True)"
      ],
      "metadata": {
        "id": "Jl6VmD-5OjxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Correr algoritmo de lluvia"
      ],
      "metadata": {
        "id": "_azTp4wlOn07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def meanspec(audio, Fs=1, wn=\"hann\", ovlp=0, wl=512, nfft=None, norm=True):\n",
        "    f, t, Zxx = signal.stft(audio, fs=Fs, window=wn, noverlap=ovlp, nperseg=wl, nfft=nfft)\n",
        "    mspec = np.mean(np.abs(Zxx), axis=1)\n",
        "    if norm:\n",
        "        mspec = mspec / max(mspec)\n",
        "    return f, mspec\n",
        "\n",
        "def calculo_PSD_promedio(df_ll, pbar=None):\n",
        "    canal = 0\n",
        "    fmin = 200\n",
        "    fmax = 11250\n",
        "    tipo_ventana = \"hann\"\n",
        "    sobreposicion = 0\n",
        "    tamano_ventana = 1024\n",
        "    nfft = tamano_ventana\n",
        "    banda_lluvia = (600, 1200)\n",
        "\n",
        "    ruta_archivo = df_ll.path_FI\n",
        "    grupo = df_ll.field_number_PR\n",
        "\n",
        "    try:\n",
        "        x, Fs = sf.read(ruta_archivo)\n",
        "        audio = x if len(x.shape) == 1 else x[:, canal]\n",
        "        puntos_minuto = Fs * 60\n",
        "        npuntos = len(audio)\n",
        "        banda = []\n",
        "\n",
        "        for seg in range(0, npuntos, puntos_minuto):\n",
        "            f, p = signal.welch(audio[seg:puntos_minuto+seg], Fs, nperseg=512, window=tipo_ventana, nfft=nfft, noverlap=sobreposicion)\n",
        "            banda.append(p[np.logical_and(f >= banda_lluvia[0], f <= banda_lluvia[1])])\n",
        "\n",
        "        banda = np.concatenate(banda)\n",
        "        PSD_medio = np.mean(banda)\n",
        "\n",
        "        f, mspec = meanspec(audio, Fs, tipo_ventana, sobreposicion, tamano_ventana, nfft)\n",
        "        cond = np.logical_and(f > fmin, f < fmax)\n",
        "        feats = list(mspec[cond])\n",
        "        freqs = list(f[cond])\n",
        "        titulos = [f\"mPSD_{int(freqs[i])}\" for i in range(len(freqs))]\n",
        "\n",
        "        zip_iterator = zip(titulos, feats)\n",
        "        if pbar is not None:\n",
        "            pbar.update(1)\n",
        "\n",
        "        return ruta_archivo, dict(zip_iterator), PSD_medio, 'NO', grupo\n",
        "    except:\n",
        "        if pbar is not None:\n",
        "            pbar.update(1)\n",
        "        print(f\"El archivo {ruta_archivo} está corrupto.\")\n",
        "        return ruta_archivo, {}, 0, 'YES', grupo\n",
        "\n",
        "def _apply_df(args):\n",
        "    df, func = args\n",
        "    res = df.apply(func, axis=1)\n",
        "    return res\n",
        "\n",
        "def regla_decision(x, umbral):\n",
        "    if x != 0:\n",
        "        return \"NO\" if x < umbral else \"YES\"\n",
        "    return \"PSD medio 0\"\n",
        "\n",
        "def algoritmo_lluvia_imp(df_ind):\n",
        "    df_lluvia = df_ind.loc[df_ind.damaged_FI == 'NO', :].copy()\n",
        "    df_no_lluvia = df_ind.loc[df_ind.damaged_FI == 'YES', :].copy()\n",
        "\n",
        "    PSD_medio = np.array(df_lluvia.PSD_medio.values).astype(np.float64)\n",
        "    PSD_medio_sin_ceros = PSD_medio[PSD_medio > 0]\n",
        "    umbral = (np.mean(PSD_medio_sin_ceros) + stats.mstats.gmean(PSD_medio_sin_ceros)) / 2\n",
        "\n",
        "    df_lluvia['rain_FI'] = df_lluvia.PSD_medio.apply(regla_decision, umbral=umbral)\n",
        "    df_lluvia = df_lluvia.drop(['PSD_medio'], axis=1)\n",
        "\n",
        "    df_no_lluvia['rain_FI'] = 'Archivo corrupto'\n",
        "    df_no_lluvia = df_no_lluvia.drop(['PSD_medio'], axis=1)\n",
        "\n",
        "    df_indices_lluvia = pd.concat([df_lluvia, df_no_lluvia])\n",
        "    assert df_indices_lluvia.shape[0] == df_ind.shape[0]\n",
        "    return df_indices_lluvia\n",
        "\n",
        "# **Inicio del análisis**\n",
        "if __name__ == '__main__':\n",
        "    dict_df = {\"field_number_PR\": [], \"name_FI\": [], \"path_FI\": []}\n",
        "\n",
        "    print(\"Inventariando archivos...\")\n",
        "    start_time = time.time()\n",
        "    for (root, dirs, files) in os.walk(ruta_datos):\n",
        "        for f in files:\n",
        "            if any([f\".{formato}\" in f for formato in formatos]) and not f.startswith(\".\"):\n",
        "                dict_df[\"field_number_PR\"].append(os.path.basename(root))\n",
        "                dict_df[\"name_FI\"].append(f)\n",
        "                dict_df[\"path_FI\"].append(os.path.join(root, f))\n",
        "    df = pd.DataFrame(dict_df)\n",
        "    print(f\"{len(df)} archivos encontrados\")\n",
        "\n",
        "    df = df.loc[df.field_number_PR.apply(lambda x: x not in exclude_these_sites), :]\n",
        "    print(f\"{len(df)} archivos después de excluir sitios\")\n",
        "\n",
        "    print(\"Calculando índices...\")\n",
        "    workers = min(len(df), n_cores)\n",
        "    df_split = np.array_split(df, workers)\n",
        "\n",
        "    with Pool(processes=workers) as pool:\n",
        "        result = list(tqdm.tqdm(pool.imap(_apply_df, [(d, calculo_PSD_promedio) for d in df_split]), total=len(df_split)))\n",
        "\n",
        "    x = pd.concat(result)\n",
        "    x = np.array(list(zip(*x))).T\n",
        "\n",
        "    df_ind = pd.DataFrame(list(x[:, 1]))\n",
        "    df_ind['path_FI'] = x[:, 0]\n",
        "    df_ind['PSD_medio'] = x[:, 2]\n",
        "    df_ind['damaged_FI'] = x[:, 3]\n",
        "    df_ind['grupo'] = x[:, 4]\n",
        "\n",
        "    df_lluvias = []\n",
        "    for i in tqdm.tqdm(df_ind['grupo'].unique()):\n",
        "        df_tmp = df_ind[df_ind.grupo == i]\n",
        "        df_lluvias.append(algoritmo_lluvia_imp(df_tmp))\n",
        "\n",
        "    df_indices_lluvia = pd.concat(df_lluvias)\n",
        "    assert len(df) == len(df_indices_lluvia)\n",
        "\n",
        "    df_y = df.merge(df_indices_lluvia, how='left', on='path_FI')\n",
        "    df_y = df_y.drop(['path_FI', 'damaged_FI', 'grupo'], axis=1)\n",
        "\n",
        "    path_file = os.path.join(folder_rain, name_file)\n",
        "    print(f\"Guardando resultados en {path_file}...\")\n",
        "    df_y.to_excel(path_file, index=False)\n",
        "    print(f\"Resultados guardados en {path_file}\")\n",
        "    print(f\"Tiempo de ejecución: {str(timedelta(seconds=time.time() - start_time))}\")\n"
      ],
      "metadata": {
        "id": "9UvxPFVRBONf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graficar eventos de lluvia y archivos defectuosos por sitio y fecha"
      ],
      "metadata": {
        "id": "xOWdonjKGlxU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar las bibliotecas necesarias\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Ruta al archivo Excel en Google Drive\n",
        "file_path = '/content/drive/MyDrive/Curso_Ecologia_Paisaje_Ecoacustica/Geofonias/Resultado_lluvia.xlsx'\n",
        "\n",
        "# Cargamos el archivo de Excel en un DataFrame\n",
        "ResultadosLluvia = pd.read_excel(file_path)\n",
        "\n",
        "# Función para convertir el nombre del archivo en fecha y hora\n",
        "def convertir_nombre_fecha(nombre_archivo):\n",
        "    fecha_hora_str = nombre_archivo.split('_')[1] + '_' + nombre_archivo.split('_')[2].replace('.WAV', '')\n",
        "    return pd.to_datetime(fecha_hora_str, format='%Y%m%d_%H%M%S')\n",
        "\n",
        "# Convertir 'name_FI' a datetime\n",
        "ResultadosLluvia['name_FI'] = ResultadosLluvia['name_FI'].apply(convertir_nombre_fecha)\n",
        "\n",
        "# Convertir 'field_number_PR' a tipo categórico\n",
        "ResultadosLluvia['field_number_PR'] = ResultadosLluvia['field_number_PR'].astype('category')\n",
        "\n",
        "# Definir el orden de las categorías para 'rain_FI'\n",
        "categorias = ['YES', 'NO', 'Tiempo diferente', 'Archivo corrupto']\n",
        "ResultadosLluvia['rain_FI'] = pd.Categorical(ResultadosLluvia['rain_FI'], categories=categorias, ordered=True)\n",
        "\n",
        "# Crear la gráfica\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Dibujar todos los puntos excepto donde rain_FI es 'YES'\n",
        "sns.scatterplot(data=ResultadosLluvia[ResultadosLluvia['rain_FI'] != 'YES'], x='name_FI', y='field_number_PR', hue='rain_FI',\n",
        "                palette={'YES': 'blue', 'NO': 'grey', 'Tiempo diferente': 'orange', 'Archivo corrupto': 'red'})\n",
        "\n",
        "# Dibujar solo los puntos donde rain_FI es 'YES' para que se vean encima\n",
        "sns.scatterplot(data=ResultadosLluvia[ResultadosLluvia['rain_FI'] == 'YES'], x='name_FI', y='field_number_PR',\n",
        "                color='blue')\n",
        "\n",
        "# Personalizar la gráfica\n",
        "plt.title('Distribución de eventos de lluvia')\n",
        "plt.xlabel('Fecha')\n",
        "plt.ylabel('Sitio')\n",
        "plt.xticks(rotation=90)\n",
        "plt.legend(title='Lluvia', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "# Guardar la gráfica como archivo PNG en Google Drive\n",
        "output_path = '/content/drive/MyDrive/Curso_Ecologia_Paisaje_Ecoacustica/Geofonias/DistribucionEventosLluvia.png'\n",
        "plt.savefig(output_path, bbox_inches='tight')\n",
        "\n",
        "# Mostrar la gráfica\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ngrXcgHmGl8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graficar lluvia por horas"
      ],
      "metadata": {
        "id": "gplTejqgI5ef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Ruta del archivo Excel en Google Drive\n",
        "file_path = '/content/drive/MyDrive/Curso_Ecologia_Paisaje_Ecoacustica/Geofonias/Resultado_lluvia.xlsx'\n",
        "\n",
        "# Cargamos el archivo de Excel en un DataFrame\n",
        "ResultadosLluvia = pd.read_excel(file_path)\n",
        "\n",
        "# Función para convertir el nombre del archivo en hora\n",
        "def convertir_nombre_hora(nombre_archivo):\n",
        "    hora_str = nombre_archivo.split('_')[2].replace('.WAV', '')\n",
        "    return int(hora_str[:2])\n",
        "\n",
        "# Convertir 'name_FI' a hora\n",
        "ResultadosLluvia['hora_FI'] = ResultadosLluvia['name_FI'].apply(convertir_nombre_hora)\n",
        "\n",
        "# Convertir 'field_number_PR' a tipo categórico\n",
        "ResultadosLluvia['field_number_PR'] = ResultadosLluvia['field_number_PR'].astype('category')\n",
        "\n",
        "# Definir el orden de las categorías para 'rain_FI'\n",
        "categorias = ['YES', 'NO', 'Tiempo diferente', 'Archivo corrupto']\n",
        "ResultadosLluvia['rain_FI'] = pd.Categorical(ResultadosLluvia['rain_FI'], categories=categorias, ordered=True)\n",
        "\n",
        "# Agrupar por hora y contar los eventos de lluvia\n",
        "hora_lluvia = ResultadosLluvia[ResultadosLluvia['rain_FI'] == 'YES'].groupby('hora_FI').size().reindex(range(24), fill_value=0).reset_index(name='count')\n",
        "\n",
        "# Crear la gráfica\n",
        "plt.figure(figsize=(10, 6))\n",
        "barplot = sns.barplot(data=hora_lluvia, x='hora_FI', y='count', palette='Blues_d')\n",
        "\n",
        "# Personalizar la gráfica\n",
        "plt.title('Distribución de eventos de lluvia por hora')\n",
        "plt.xlabel('Hora')\n",
        "plt.ylabel('Número de eventos de lluvia')\n",
        "plt.xticks(rotation=90)\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "# Ajustar la paleta de colores para que sea más oscura con más eventos\n",
        "norm = plt.Normalize(min(hora_lluvia['count']), max(hora_lluvia['count']))\n",
        "for i, bar in enumerate(barplot.patches):\n",
        "    bar.set_facecolor(plt.cm.Blues(norm(bar.get_height())))\n",
        "\n",
        "# Guardar la gráfica como archivo PNG en Google Drive\n",
        "output_path = '/content/drive/MyDrive/Curso_Ecologia_Paisaje_Ecoacustica/Geofonias/DistribucionEventosLluviaPorHora.png'\n",
        "plt.savefig(output_path, bbox_inches='tight')\n",
        "\n",
        "# Mostrar la gráfica\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_XTYr_SuI6x4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conteo final de archivos"
      ],
      "metadata": {
        "id": "CDb_9vqnJNZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Ruta del archivo Excel en Google Drive\n",
        "file_path = '/content/drive/MyDrive/Curso_Ecologia_Paisaje_Ecoacustica/Geofonias/Resultado_lluvia.xlsx'\n",
        "\n",
        "# Cargamos el archivo de Excel en un DataFrame\n",
        "ResultadosLluvia = pd.read_excel(file_path)\n",
        "\n",
        "# Agrupamos los datos por 'field_number_PR' y 'rain_FI', y contamos las ocurrencias\n",
        "conteo_por_carpeta = ResultadosLluvia.groupby(['field_number_PR', 'rain_FI']).size().unstack(fill_value=0)\n",
        "\n",
        "# Calculamos el total general por etiqueta 'rain_FI'\n",
        "total_general = ResultadosLluvia['rain_FI'].value_counts()\n",
        "\n",
        "# Imprimimos los resultados\n",
        "print(\"Conteo por carpeta (field_number_PR):\")\n",
        "print(conteo_por_carpeta)\n",
        "\n",
        "print(\"\\nTotal general por etiqueta de lluvia (rain_FI):\")\n",
        "print(total_general)\n",
        "\n",
        "# Guardar los resultados en un archivo Excel\n",
        "output_counts_path = '/content/drive/MyDrive/Curso_Ecologia_Paisaje_Ecoacustica/Geofonias/Conteo_Lluvia.xlsx'\n",
        "with pd.ExcelWriter(output_counts_path) as writer:\n",
        "    conteo_por_carpeta.to_excel(writer, sheet_name='Conteo por Carpeta')\n",
        "    total_general.to_frame(name='Total General').to_excel(writer, sheet_name='Total General')\n",
        "\n",
        "print(f\"Resultados guardados en: {output_counts_path}\")\n"
      ],
      "metadata": {
        "id": "N-s5jjHFJaa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EXTRACCIÓN DE ARCHIVOS\n",
        "\n",
        "Ahora, se generará una estraccción de los archivo que NO tengan lluvia y que no estén dañados"
      ],
      "metadata": {
        "id": "W731yPC4KGpC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8hD3fi3jNsV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Ruta del archivo Excel en Google Drive\n",
        "file_path = '/content/drive/MyDrive/Curso_Ecologia_Paisaje_Ecoacustica/Geofonias/Resultado_lluvia.xlsx'\n",
        "\n",
        "# Cargamos el archivo de Excel en un DataFrame\n",
        "ResultadosLluvia = pd.read_excel(file_path)\n",
        "\n",
        "# Filtramos para obtener solo los archivos donde rain_FI es 'NO'\n",
        "archivos_sin_lluvia = ResultadosLluvia[ResultadosLluvia['rain_FI'] == 'NO']\n",
        "\n",
        "# Directorio raíz donde están los subdirectorios con los archivos de audio originales en Google Drive\n",
        "root_directory_path = '/content/drive/MyDrive/CursoPaisajeAudios/'  #### Introudcir la ruta correspondiente\n",
        "\n",
        "# Directorio donde se copiarán los archivos en Google Drive\n",
        "new_directory_path = '/content/drive/MyDrive/Curso_Ecologia_Paisaje_Ecoacustica/Audios_SinLluvia'\n",
        "\n",
        "# Copiar los archivos manteniendo la estructura de subcarpetas\n",
        "for file_name in archivos_sin_lluvia['name_FI']:\n",
        "    # Asegúrate de que file_name es una cadena\n",
        "    file_name_str = str(file_name).strip()\n",
        "    archivo_encontrado = False\n",
        "\n",
        "    # Buscar el archivo en el directorio raíz y sus subdirectorios\n",
        "    for subdir, _, files in os.walk(root_directory_path):\n",
        "        if file_name_str in files:\n",
        "            full_file_path = os.path.join(subdir, file_name_str)\n",
        "            # Conservar la estructura de subcarpetas para la nueva ubicación\n",
        "            subfolder_structure = os.path.relpath(subdir, root_directory_path)\n",
        "            new_subfolder_path = os.path.join(new_directory_path, subfolder_structure)\n",
        "            if not os.path.exists(new_subfolder_path):\n",
        "                os.makedirs(new_subfolder_path)\n",
        "            destination_file_path = os.path.join(new_subfolder_path, file_name_str)\n",
        "            shutil.copy(full_file_path, destination_file_path)\n",
        "            archivo_encontrado = True\n",
        "            print(f\"Copiado: {destination_file_path}\")\n",
        "            break\n",
        "\n",
        "    if not archivo_encontrado:\n",
        "        print(f\"No se encontró el archivo: {file_name_str}\")\n",
        "\n",
        "print(\"Proceso de copiado finalizado.\")\n"
      ],
      "metadata": {
        "id": "r0MpHmvLLKD8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}